import asyncio
import gradio as gr
from typing import Optional
from contextlib import AsyncExitStack
import json
import os
from dotenv import load_dotenv

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from mcp.client.sse import sse_client

curr_dir = os.path.dirname(os.path.abspath(__file__))

CONFIG_PATH = os.path.join(curr_dir, "mcp.json")
ENV_PATH = ".env"

load_dotenv()

from openai import OpenAI

api_key = os.environ["DEEPSEEK_API_KEY"]
base_url = os.environ["DEEPSEEK_API_BASE"]
model_type = os.environ["DEEPSEEK_MODEL"]


class MCPClient:
    def __init__(self):
        self.session: Optional[object] = None
        self.exit_stack = AsyncExitStack()
        self.sessions = {}
        self.tools_map = {}
        self.openai_client = OpenAI(api_key=api_key, base_url=base_url)

    async def connect_to_sse_server_by_config(self, config_path: str = CONFIG_PATH):
        try:
            with open(config_path, 'r') as f:
                config = json.load(f)

            if 'mcpServers' not in config:
                raise ValueError("æœåŠ¡ç«¯é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘ mcpServers å­—æ®µ")

            mcp_servers = config['mcpServers']
            connect_tasks = []
            for server_id, server_info in mcp_servers.items():
                if 'url' not in server_info:
                    print(f"è­¦å‘Š: æœåŠ¡å™¨ {server_id} ç¼ºå°‘ url é…ç½®ï¼Œè·³è¿‡")
                    continue
                connect_tasks.append(self._connect_single_sse_server(server_id, server_info))

            results = await asyncio.gather(*connect_tasks, return_exceptions=True)
            success_count = sum(1 for r in results if not isinstance(r, Exception))
            print(f"\næˆåŠŸè¿æ¥ {success_count} ä¸ªSSEæœåŠ¡å™¨ (å…±å°è¯• {len(connect_tasks)} ä¸ª)")
            if self.sessions:
                await self.list_tools()
            else:
                print("è­¦å‘Š: æ²¡æœ‰æˆåŠŸè¿æ¥ä»»ä½•æœåŠ¡å™¨")
        except FileNotFoundError:
            print(f"é”™è¯¯: æœåŠ¡ç«¯é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨")
        except json.JSONDecodeError:
            print(f"é”™è¯¯: æœåŠ¡ç«¯é…ç½®æ–‡ä»¶ {config_path} ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼")
        except Exception as e:
            print(f"è¿æ¥SSEæœåŠ¡å™¨æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

    async def _connect_single_sse_server(self, server_id: str, server_info: dict):
        try:
            server_url = server_info['url']
            # streams_context = sse_client(url=server_url)
            # streams = await streams_context.__aenter__()
            # session_context = ClientSession(*streams)
            # session = await session_context.__aenter__()

            # ä¿®æ”¹åçš„
            streams = await self.exit_stack.enter_async_context(sse_client(url=server_url))
            session = await self.exit_stack.enter_async_context(ClientSession(*streams))

            await session.initialize()
            self.sessions[server_id] = {
                "session": session,
                "url": server_url
            }
            response = await session.list_tools()
            for tool in response.tools:
                self.tools_map[tool.name] = server_id
            print(f"æˆåŠŸè¿æ¥åˆ°æœåŠ¡å™¨ {server_id} ({server_url})")
        except Exception as e:
            print(f"è¿æ¥æœåŠ¡å™¨ {server_id} å¤±è´¥: {str(e)}")
            raise

    async def list_tools(self):
        if not self.sessions:
            print("æ²¡æœ‰å·²è¿æ¥çš„æœåŠ¡ç«¯")
            return
        print("å·²è¿æ¥çš„æœåŠ¡ç«¯åˆ—è¡¨:")
        for server_id, session_info in self.sessions.items():
            print(f"æœåŠ¡ç«¯: {server_id}, URL: {session_info['url']}")

    async def process_query(self, query: str, update_output: callable):
        messages = [{"role": "user", "content": query}]

        async def log(text):
            await update_output(text + "\n")
            print(text)

        await log(f"ğŸ”µ å¼€å§‹å¤„ç†æŸ¥è¯¢: {query}")

        available_tools = []
        for tool_name, server_id in self.tools_map.items():
            session = self.sessions[server_id]["session"]
            response = await session.list_tools()
            for tool in response.tools:
                if tool.name == tool_name:
                    available_tools.append({
                        "type": "function",
                        "function": {
                            "name": tool.name,
                            "description": tool.description,
                            "parameters": tool.inputSchema
                        }
                    })

        await log(f"ğŸ› ï¸ å¯ç”¨å·¥å…·åˆ—è¡¨:\n{json.dumps(available_tools, indent=2, ensure_ascii=False)}")

        await log("ğŸ¤– æ­£åœ¨è°ƒç”¨æ¨¡å‹APIè¿›è¡Œåˆå§‹åˆ†æ...")
        model_response = self.openai_client.chat.completions.create(
            model=model_type,
            max_tokens=1000,
            messages=messages,
            tools=available_tools if available_tools else None
        )
        assistant_message = model_response.choices[0].message
        messages.append(assistant_message.model_dump())

        await log(f"ğŸ’¡ æ¨¡å‹åˆå§‹å“åº”:\n{json.dumps(assistant_message.model_dump(), indent=2, ensure_ascii=False)}")

        if assistant_message.tool_calls:
            for tool_call in assistant_message.tool_calls:
                await log(f"ğŸ”§ å‡†å¤‡è°ƒç”¨å·¥å…·: {tool_call}")
                tool_name = tool_call.function.name
                tool_args = json.loads(tool_call.function.arguments)

                await log(f"âš™ï¸ å‡†å¤‡è°ƒç”¨å·¥å…·: {tool_name}")
                await log(f"ğŸ“‹ å·¥å…·å‚æ•°:\n{json.dumps(tool_args, indent=2, ensure_ascii=False)}")

                server_id = self.tools_map[tool_name]
                session = self.sessions[server_id]["session"]

                await log(f"ğŸ”— è¿æ¥åˆ°æœåŠ¡å™¨: {server_id}")
                try:
                    await log("ğŸ”„ æ­£åœ¨æ‰§è¡Œå·¥å…·è°ƒç”¨...")
                    result = await session.call_tool(tool_name, tool_args)
                    await log(f"âœ… å·¥å…·è°ƒç”¨æˆåŠŸ! ç»“æœ:\n{result}")
                    
                    messages.append({
                        "role": "tool",
                        "content": f"{result}",
                        "tool_call_id": tool_call.id,
                        "name": tool_name
                    })
                except Exception as e:
                    error_msg = f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
                    await log(error_msg)
                    messages.append({
                        "role": "tool",
                        "content": error_msg,
                        "tool_call_id": tool_call.id,
                        "name": tool_name
                    })

            await log("\nğŸ”„ æ­£åœ¨è·å–æ¨¡å‹æœ€ç»ˆå“åº”...")
            final_response = self.openai_client.chat.completions.create(
                model=model_type,
                max_tokens=1000,
                messages=messages,
            )
            final_message = final_response.choices[0].message
            messages.append(final_message.model_dump())
            await log(f"âœ¨ æœ€ç»ˆå“åº”:\n{final_message.content}")
            
            return final_message.content

        await log("ğŸ“ æ¨¡å‹ç›´æ¥è¿”å›ç»“æœ:")
        return assistant_message.content

    async def cleanup(self):
        await self.exit_stack.aclose()



    async def disconnect_all(self):
        try:
            await self.exit_stack.aclose()  # è‡ªåŠ¨æ¸…ç†æ‰€æœ‰ context
            self.exit_stack = AsyncExitStack()  # é‡ç½®
            self.sessions = {}
            self.tools_map = {}
            print("âœ… æ‰€æœ‰æœåŠ¡å™¨è¿æ¥å·²æ–­å¼€")
            return "âœ… æ‰€æœ‰æœåŠ¡å™¨è¿æ¥å·²æ–­å¼€"
        except Exception as e:
            error_msg = f"âŒ æ¸…ç†ä¸Šä¸‹æ–‡å‡ºé”™: {str(e)}"
            print(error_msg)
            return error_msg





client = MCPClient()


async def gradio_interface(query: str):
    output_queue = asyncio.Queue()
    full_output = ""

    async def update_output(new_text: str):
        await output_queue.put(new_text)

    if not client.sessions:
        await client.connect_to_sse_server_by_config()

    process_task = asyncio.create_task(client.process_query(query, update_output))
    get_output_task = asyncio.create_task(output_queue.get())

    yield full_output, "â³ æ­£åœ¨ç”Ÿæˆå›ç­”..."

    try:
        while True:
            done, _ = await asyncio.wait(
                [get_output_task, process_task],
                return_when=asyncio.FIRST_COMPLETED
            )

            if get_output_task in done:
                new_text = get_output_task.result()
                full_output += new_text
                yield full_output, "â³ æ­£åœ¨ç”Ÿæˆå›ç­”..."
                get_output_task = asyncio.create_task(output_queue.get())

            if process_task in done:
                if not process_task.cancelled():
                    result = await process_task
                    full_output += f"\n\nâœ… å¤„ç†å®Œæˆ:\n{result}"
                    yield full_output, "âœ… å›ç­”å®Œæˆ"
                break

    except Exception as e:
        full_output += f"\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}"
        yield full_output, f"âŒ é”™è¯¯: {str(e)}"
    finally:
        if not process_task.done():
            process_task.cancel()





#æ–°å¢çš„
async def connect_servers():
    await client.connect_to_sse_server_by_config()
    return "âœ… å·²å°è¯•è¿æ¥æ‰€æœ‰æœåŠ¡ç«¯"

async def disconnect_servers():
    await client.disconnect_all()
    return "âœ… æ‰€æœ‰æœåŠ¡ç«¯è¿æ¥å·²æ–­å¼€"

async def get_tool_list_display():
    try:
        if not client.sessions:
            return "âš ï¸ å½“å‰æœªè¿æ¥ä»»ä½•æœåŠ¡ç«¯"
        display = []
        for server_id, session_info in client.sessions.items():
            display.append(f"### ğŸ”Œ æœåŠ¡ç«¯ï¼š`{server_id}` ({session_info['url']})")
            session = session_info["session"]
            try:
                response = await session.list_tools()
                for tool in response.tools:
                    display.append(f"- ğŸ› ï¸ **{tool.name}**: {tool.description}")
            except Exception as e:
                display.append(f"âš ï¸ æ— æ³•åˆ—å‡ºå·¥å…·: {str(e)}")
            display.append("\n")
        return "\n".join(display)
    except Exception as e:
        return f"âŒ å·¥å…·åˆ—è¡¨åˆ·æ–°å¤±è´¥: {str(e)}"



def load_config_file():
    if os.path.exists(CONFIG_PATH):
        with open(CONFIG_PATH, "r", encoding="utf-8") as f:
            return f.read()
    return "{}"

def save_config_file(content: str):
    try:
        json.loads(content)
        with open(CONFIG_PATH, "w", encoding="utf-8") as f:
            f.write(content)
        print("âœ… æœåŠ¡ç«¯é…ç½®æ–‡ä»¶ä¿å­˜æˆåŠŸï¼")
        return "âœ… æœåŠ¡ç«¯é…ç½®æ–‡ä»¶ä¿å­˜æˆåŠŸï¼"
    except json.JSONDecodeError:
        print("âŒ ä¿å­˜å¤±è´¥ï¼šæ— æ•ˆçš„ JSON æ ¼å¼")
        return "âŒ ä¿å­˜å¤±è´¥ï¼šæ— æ•ˆçš„ JSON æ ¼å¼"
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥ï¼š{str(e)}")
        return f"âŒ ä¿å­˜å¤±è´¥ï¼š{str(e)}"

def load_env_file():
    if os.path.exists(ENV_PATH):
        with open(ENV_PATH, "r", encoding="utf-8") as f:
            return f.read()
    return ""

def save_env_file(content: str):
    try:
        with open(ENV_PATH, "w", encoding="utf-8") as f:
            f.write(content)
        return "âœ… ç¯å¢ƒå˜é‡æ–‡ä»¶ä¿å­˜æˆåŠŸï¼"
    except Exception as e:
        return f"âŒ ä¿å­˜å¤±è´¥ï¼š{str(e)}"



with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ› ï¸ MCP å®¢æˆ·ç«¯å·¥å…·è°ƒç”¨æ¼”ç¤º---author : AIå°æ–°")

    with gr.Tab("ğŸ’¬ ä¸»ç•Œé¢"):
        with gr.Row():
            input_text = gr.Textbox(label="è¾“å…¥æŸ¥è¯¢", placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...", lines=3)
        with gr.Row():
            submit_btn = gr.Button("å¼€å§‹é—®ç­”", variant="primary")
        with gr.Row():
            status_box = gr.Textbox(label="é—®ç­”çŠ¶æ€", value="", interactive=False)
        with gr.Row():
            output_text = gr.Textbox(label="é—®ç­”è¿‡ç¨‹", interactive=False, lines=20, autoscroll=True)

        

    with gr.Tab("âš™ï¸ æœåŠ¡ç«¯é…ç½®æ–‡ä»¶"):
        gr.Markdown("### ç¼–è¾‘ mcp.json æœåŠ¡ç«¯é…ç½®æ–‡ä»¶")
        config_editor = gr.Code(value=load_config_file(), language="json", lines=20)
        save_config_btn = gr.Button("ä¿å­˜é…ç½®", variant="secondary")
        config_status = gr.Textbox(label="çŠ¶æ€", interactive=False)

    # with gr.Tab("ğŸ”‘ ç¯å¢ƒå˜é‡"):
    #     gr.Markdown("### ç¼–è¾‘ .env æ–‡ä»¶")
    #     env_editor = gr.Code(value=load_env_file(), language="python", lines=10)
    #     save_env_btn = gr.Button("ä¿å­˜ç¯å¢ƒå˜é‡", variant="secondary")
    #     env_status = gr.Textbox(label="çŠ¶æ€", interactive=False)

    with gr.Tab("ğŸ”— æœåŠ¡ç«¯æ§åˆ¶"):
        gr.Markdown("### è¿æ¥å’Œæ–­å¼€ SSE æœåŠ¡å™¨")
        connect_btn = gr.Button("ğŸ”Œ è¿æ¥æ‰€æœ‰æœåŠ¡ç«¯", variant="primary")
        disconnect_btn = gr.Button("âŒ æ–­å¼€æ‰€æœ‰æœåŠ¡ç«¯", variant="stop")
        connect_status = gr.Textbox(label="è¿æ¥çŠ¶æ€", interactive=False)

    with gr.Tab("ğŸ“¦ å¯ç”¨å·¥å…·åˆ—è¡¨"):
        gr.Markdown("### å½“å‰å·²è¿æ¥æœåŠ¡ç«¯çš„å·¥å…·æ¸…å•")
        refresh_tools_btn = gr.Button("ğŸ”„ åˆ·æ–°å·¥å…·åˆ—è¡¨")
        tools_display = gr.Markdown("ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®æŸ¥çœ‹å¯ç”¨å·¥å…·")


    gr.Markdown("# github å¼€æºåœ°å€ï¼š https://github.com/aixiaoxin123/mcp_demo_project ")

    # æ–°å¢çš„    
    connect_servers()
    # ç»‘å®šäº‹ä»¶

    submit_btn.click(gradio_interface, inputs=[input_text], outputs=[output_text, status_box])
    save_config_btn.click(save_config_file, inputs=[config_editor], outputs=[config_status])
    # save_env_btn.click(save_env_file, inputs=[env_editor], outputs=[env_status])
    connect_btn.click(connect_servers, outputs=[connect_status])
    disconnect_btn.click(disconnect_servers, outputs=[connect_status])

    refresh_tools_btn.click(get_tool_list_display, outputs=[tools_display])


if __name__ == "__main__":

    demo.launch(debug=True, share=False, inbrowser=True, server_name="0.0.0.0")